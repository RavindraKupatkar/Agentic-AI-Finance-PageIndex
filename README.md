# ğŸš€ LangGraph RAG System

> **Production-Grade Document Q&A with SOLID Principles**

Upload PDF â†’ Ask Questions â†’ Get AI Answers

---

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ğŸ‘¤ USER INTERFACES                            â”‚
â”‚   ğŸŒ Streamlit UI (Web) â”‚ ğŸ–¥ï¸ CLI (Command Line)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ“¥ INGESTION GRAPH                       â”‚
â”‚  START â†’ extract_text â†’ chunk_text â†’ embed â†’ store â†’ END   â”‚
â”‚            (with real-time logging to SQLite)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ğŸ—„ï¸ ChromaDB  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    â“ QUERY GRAPH                            â”‚
â”‚  START â†’ embed_q â†’ retrieve â†’ response_generator â†’ END     â”‚
â”‚                                      ğŸ¤–                      â”‚
â”‚                            (Intelligent Agent)              â”‚
â”‚            (with confidence scoring & logging)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
capstone_project/
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                 # ğŸŒ Streamlit web interface
â”‚   â””â”€â”€ logger.py              # ğŸ“Š SQLite logging system
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # âš™ï¸ Centralized configuration
â”‚   â”œâ”€â”€ main.py                # ğŸ–¥ï¸ CLI entry point
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ state.py           # ğŸ“Š RAGState TypedDict
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pdf_service.py     # ğŸ“„ PDF extraction
â”‚   â”‚   â”œâ”€â”€ embedding_service.py  # ğŸ”¢ Embeddings
â”‚   â”‚   â”œâ”€â”€ vector_store.py    # ğŸ—„ï¸ ChromaDB
â”‚   â”‚   â”œâ”€â”€ llm_service.py     # ğŸ§  Groq LLM
â”‚   â”‚   â””â”€â”€ response_generator.py  # ğŸ¤– Response Generator Agent
â”‚   â””â”€â”€ graphs/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ nodes.py           # ğŸ”§ Node functions
â”‚       â”œâ”€â”€ ingestion_graph.py # ğŸ“¥ Ingestion StateGraph
â”‚       â””â”€â”€ query_graph.py     # â“ Query StateGraph
â”œâ”€â”€ data/                      # ğŸ“‚ PDF files
â”œâ”€â”€ tests/                     # ğŸ§ª Unit tests
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ ARCHITECTURE.md        # ğŸ“ Architecture diagrams
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **UI Framework** | Streamlit (Web Interface) |
| **Graph Framework** | LangGraph (StateGraph) |
| **PDF Processing** | PyPDF |
| **Embeddings** | Sentence-Transformers (`all-MiniLM-L6-v2`) |
| **Vector Store** | ChromaDB (persistent) |
| **LLM** | Groq (`llama-3.1-70b-versatile`) |
| **Logging** | SQLite (node execution tracking) |
| **Checkpointing** | LangGraph MemorySaver |

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd capstone_project_day_02
pip install -r requirements.txt
```

### 2. Configure API Key

```bash
cp .env.example .env
# Edit .env and add your GROQ_API_KEY
```

### 3. Run the Application

**Option A: Streamlit UI (Recommended)**
```bash
streamlit run streamlit_app/app.py
```
- ğŸ“„ Upload PDFs via drag & drop
- ğŸ’¬ Interactive query interface  
- ğŸ“Š Real-time node execution logs
- ğŸ’¾ SQLite-persisted metadata

**Option B: Command Line**
```bash
# Ingest a document
python main.py ingest data/document.pdf

# Ask questions
python main.py query "What is this about?"
```

### 4. Example: Streamlit UI

**Output:**
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ INGESTING: data/document.pdf
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  ğŸ“ Extracted 15,234 characters
  âœ‚ï¸  Created 23 chunks
  ğŸ”¢ Generated 23 embeddings
  ğŸ’¾ Stored 23 chunks in ChromaDB
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Ingested 23 chunks from document.pdf
```

### 4. Ask Questions

```bash
python main.py query "What is the main topic of this document?"
```

**Output:**
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â“ QUESTION: What is the main topic of this document?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  ğŸ”¢ Embedded question
  ğŸ” Retrieved 5 relevant chunks
  ğŸ¤– Response Generator Agent
     â”œâ”€ ğŸ¯ Confidence: 0.80
     â”œâ”€ ğŸ“š Sources Used: 5 chunks
     â””â”€ â±ï¸  Response Time: 2.3s
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… ANSWER:
The main topic of this document is...
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 5. Check Status

```bash
python main.py status
```

## ğŸ§± SOLID Principles

| Principle | Implementation |
|-----------|----------------|
| **S**ingle Responsibility | Each service handles one concern |
| **O**pen/Closed | Config dataclasses, extensible services |
| **L**iskov Substitution | Swappable embedding/LLM providers |
| **I**nterface Segregation | Focused service interfaces |
| **D**ependency Inversion | Services depend on config abstraction |

## ğŸ”„ LangGraph Graphs

### Ingestion Graph
```
START â†’ extract_text â†’ chunk_text â†’ embed_chunks â†’ store_chunks â†’ END
```

### Query Graph (with Memory)
```
START â†’ embed_question â†’ retrieve_chunks â†’ response_generator_agent â†’ END
                                                     ğŸ¤–
                                          (Intelligent Response Agent)
                                                     â”‚
                                            [Metrics & Confidence]
                                                     â”‚
                                              [MemorySaver]
```

## ğŸ“¦ Services

| Service | Responsibility |
|---------|---------------|
| `PDFService` | Extract text from PDF, chunk text |
| `EmbeddingService` | Generate text embeddings (singleton) |
| `VectorStoreService` | ChromaDB CRUD operations (singleton) |
| `LLMService` | Low-level LLM API calls (singleton) |
| `ResponseGeneratorService` | ğŸ¤– Intelligent response generation with metrics & confidence |

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test
pytest tests/test_services.py -v
```

## ğŸ“š Python API

```python
from src.graphs import ingest_pdf, ask_question

# Ingest a document
result = ingest_pdf("data/report.pdf")
print(result)  # âœ… Ingested 45 chunks from report.pdf

# Ask questions with conversation memory
answer = ask_question(
    "What are the key findings?",
    thread_id="session_001"
)
print(answer)
```

## âš™ï¸ Configuration

All settings in `src/config.py`:

```python
# Chunking
CHUNK_SIZE = 800
CHUNK_OVERLAP = 200

# Embeddings
EMBEDDING_MODEL = "all-MiniLM-L6-v2"

# Retrieval
TOP_K = 5

# LLM
LLM_MODEL = "llama-3.1-70b-versatile"
TEMPERATURE = 0.3
```

## ğŸ“ Architecture Diagrams

See [`docs/ARCHITECTURE.md`](docs/ARCHITECTURE.md) for detailed Mermaid diagrams including:
- System Overview
- Ingestion Graph Flow
- Query Graph Flow
- Data Flow Sequence
- SOLID Principles Mindmap

---

**Built for ADCET Agentic AI Workshop - Day 2 Capstone Project**

*Framework: LangGraph | LLM: Groq | Vector Store: ChromaDB*
